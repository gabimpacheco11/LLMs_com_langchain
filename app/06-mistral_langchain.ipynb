{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11e92575",
   "metadata": {},
   "source": [
    "## Documentação sobre Mistral\n",
    "https://docs.mistral.ai/capabilities/completion/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b326e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84f4f3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "chat = ChatMistralAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0746e142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Olá! Eu sou uma IA desenvolvida para ajudar a responder perguntas e fornecer informações. Em relação à sua pergunta, eu não \"venho\" de algum lugar no sentido físico, uma vez que sou uma criação digital. Meu código e algoritmos foram criados e desenvolvidos por pessoas, mas não tenho um local de origem no mundo físico.' additional_kwargs={} response_metadata={'token_usage': {'prompt_tokens': 18, 'total_tokens': 124, 'completion_tokens': 106}, 'model_name': 'mistral-small', 'model': 'mistral-small', 'finish_reason': 'stop'} id='run-74b7d331-bdd6-4a59-8748-dab23cd3ba10-0' usage_metadata={'input_tokens': 18, 'output_tokens': 106, 'total_tokens': 124}\n"
     ]
    }
   ],
   "source": [
    "response = chat.invoke(\"Olá, você veio de onde?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1863e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I can assist you with translating from Portuguese to German. Today is indeed a good day to study! Here's the translation:\n",
      "\n",
      "Portuguese: Hoje é um bom dia para estudar.\n",
      "German: Heute ist ein guter Tag, um zu studieren.\n"
     ]
    }
   ],
   "source": [
    "mensagens = [\n",
    "    (\"system\",\"Você é um especialista em traduzir do português para o alemão\" ),\n",
    "    (\"user\", \"Hoje é um bom dia para estudar\")\n",
    "]\n",
    "response = chat.invoke(mensagens)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f55b286e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim, sou aqui para ajudar. A acurácia (accuracy) é uma métrica de desempenho comumente utilizada em problemas de classificação de machine learning. Ela é definida como a razão entre o número de amostras corretamente classificadas e o total de amostras. Em outras palavras, a acurácia é a proporção de previsões corretas feitas pelo modelo em relação ao número total de amostras.\n",
      "\n",
      "A fórmula para calcular a acurácia é:\n",
      "\n",
      "acurácia = (número de amostras corretamente classificadas) / (total de amostras)\n",
      "\n",
      "No entanto, é importante notar que a acurácia pode ser enganadora em alguns casos, especialmente quando as classes estão desequilibradas. Nesses casos, um modelo pode ter alta acurácia apenas porque está previso corretamente a classe majoritária, enquanto as previsões para a classe minoritária estão sempre erradas. Portanto, é recomendável utilizar outras métricas de desempenho, como precisão, revocação e F1-score, além da acurácia, para avaliar o desempenho de modelos de classificação.\n"
     ]
    }
   ],
   "source": [
    "# Usando prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é um especialista em métricas de Machine Learning\"),\n",
    "    (\"user\", \"Me informe sobre o uso da métrica: {metrica}\")\n",
    "])\n",
    "\n",
    "chain = template | chat\n",
    "response = chain.invoke({\"metrica\": \"acurácia\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "310f7a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim, sou aqui para ajudar. A acurácia (accuracy) é uma métrica de desempenho comumente utilizada no aprendizado de máquina e em estatística, especialmente quando se trabalha com problemas de classificação. Ela é definida como a razão entre o número de previsões corretas e o total de instâncias a serem classificadas. Em outras palavras, a acurácia é o percentual de previsões corretas feitas pelo modelo de machine learning.\n",
      "\n",
      "A fórmula geral para calcular a acurácia é:\n",
      "\n",
      "Acurácia = (Número de previsões corretas) / (Total de instâncias)\n",
      "\n",
      "No entanto, é importante notar que a acurácia pode ser enganadora em alguns cenários, especialmente quando as classes não estão balanceadas. Nesses casos, um modelo pode alcançar alta acurácia simplesmente predizendo sempre a classe majoritária, mesmo que sua performance em outras métricas, como precisão ou recall, seja ruim.\n",
      "\n",
      "Por isso, é recomendável usar a acurácia em conjunto com outras métricas de desempenho, dependendo do problema específico em questão. Algumas alternativas à acurácia incluem a matriz de confusão, precisão, recall, F1-score, ROC AUC, e outras métricas apropriadas para o problema em questão."
     ]
    }
   ],
   "source": [
    "# Uso de Stream\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é um especialista em métricas de Machine Learning\"),\n",
    "    (\"user\", \"Me informe sobre o uso da métrica: {metrica}\")\n",
    "])\n",
    "\n",
    "chain = template | chat\n",
    "stream = chain.stream({\"metrica\": \"acurácia\"})\n",
    "for chunck in stream:\n",
    "    print(chunck.content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
